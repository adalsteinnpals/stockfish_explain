{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import chess\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import   get_FenBatchProvider, transform\n",
    "from stockfish_explain.gen_concepts import create_custom_concepts\n",
    "\n",
    "# set default plot size as large\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, vstack\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from scipy.special import expit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import (\n",
    "    ElasticNet,\n",
    "    LogisticRegression,\n",
    "    Ridge,\n",
    "    RidgeClassifier,\n",
    "    SGDRegressor,\n",
    "    LinearRegression,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "def classification_cost(y_test, y_pred):\n",
    "    y_test = np.array(y_test).astype(int)\n",
    "    y_pred = np.array(y_pred).astype(int)\n",
    "    residuals = 1 - np.abs(y_pred - y_test)\n",
    "    return np.mean(residuals) * 2 - 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df_results):\n",
    "    for target_name in df_results.target_name.unique():\n",
    "        df_results_ = df_results[df_results.target_name == target_name]\n",
    "        for model_name  in df_results_.model_name.unique():\n",
    "            # plot scores\n",
    "            plt.plot(range(len(df_results_[df_results_.model_name == model_name])), df_results_[df_results_.model_name == model_name].score, label=model_name)\n",
    "\n",
    "        # set x ticks as size   \n",
    "        plt.xticks(range(len(df_results_[df_results_.model_name == model_name])), df_results_[df_results_.model_name == model_name]['size'].astype(str))\n",
    "        plt.title(target_name)\n",
    "        plt.ylabel('score')\n",
    "        plt.xlabel('Encoder-Decoder compression size')\n",
    "        plt.ylim(0,1.1)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "activation = {}\n",
    "\n",
    "def get_activations(model, df):\n",
    "    activation_list = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "\n",
    "        data = transform([row['fen']]).cuda()\n",
    "        output = model(data)\n",
    "\n",
    "        activations_ = {'index': idx}\n",
    "        for k, v in activation.items():\n",
    "            values = v.cpu().numpy()[0]\n",
    "            if 0:\n",
    "                if k in ['input_encoder_0',]:\n",
    "                    # convert values to csr matrix with boolean values\n",
    "                    values = csr_matrix(values, dtype=bool)\n",
    "                elif k in ['decoder_3']:\n",
    "                    # convert values to csr matrix with boolean values\n",
    "                    values = csr_matrix(values > 0, dtype=bool)\n",
    "                else:\n",
    "                    # convert values to numpy float16\n",
    "                    values = values.astype(np.float16)\n",
    "            if k in ['decoder_3']:\n",
    "                values = expit(values)\n",
    "            else:\n",
    "                values = values.astype(np.float16)\n",
    "            \n",
    "            activations_[k] = values\n",
    "\n",
    "\n",
    "        # copy activation and add to activation_list\n",
    "        activation_list.append(activations_.copy())\n",
    "\n",
    "    df_activations = pd.DataFrame(activation_list)\n",
    "    return df_activations\n",
    "\n",
    "\n",
    "def train_concept_models(concept_models, input_names, target_names, df_activations, df, undersample, test_size, metric, verbose = 0):\n",
    "    results = []\n",
    "    for concept_model in concept_models:\n",
    "        for input_name in input_names:\n",
    "            for target_name in target_names:\n",
    "\n",
    "                model_name = f\"{concept_model.__class__.__name__}\"\n",
    "\n",
    "                X = df_activations[input_name].tolist()\n",
    "                y = df[target_name].tolist()\n",
    "                print(f\"X: {input_name}, y: {target_name}, model_name: .{model_name}\")\n",
    "\n",
    "                # if X is scipy.sparse.csr_matrix, vstack it \n",
    "                if isinstance(X[0], csr_matrix):\n",
    "                    X = vstack(X).astype(np.float32)\n",
    "                    size = X.shape[1]\n",
    "                else:\n",
    "                    size = len(X[0])\n",
    "\n",
    "                # change type of y to int\n",
    "                y = np.array(y).astype(int)\n",
    "\n",
    "                if target_name == 'white_queen':\n",
    "                    # is y larger than 0\n",
    "                    y = y > 0\n",
    "\n",
    "                # fit and apply the transform\n",
    "                X, y = undersample.fit_resample(X, y)\n",
    "\n",
    "\n",
    "                # split into train and test sets \n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, test_size=test_size, random_state=42, stratify=y\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "                concept_model.fit(X_train, list(y_train))\n",
    "                y_pred = concept_model.predict(X_test)\n",
    "\n",
    "                score = metric(y_test, y_pred)\n",
    "\n",
    "                # calculate confusion matrix\n",
    "                matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "                if verbose:\n",
    "                    print(f'Target value counts: {pd.Series(y_train).value_counts()}')\n",
    "                    print(f'Target value counts: {pd.Series(y_test).value_counts()}')\n",
    "                    print(f'input shape: {size}')\n",
    "                    print(matrix)\n",
    "                    print(score)\n",
    "\n",
    "                results_ = {'model_name': model_name,\n",
    "                            'input_name': input_name, \n",
    "                            'target_name': target_name,\n",
    "                            'score': score, \n",
    "                            'size': size}\n",
    "                results.append(results_)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df from sqlite db\n",
    "conn = sqlite3.connect('chess_auto_encoder.db')\n",
    "df = pd.read_sql_query('select * from fen_concept_df', conn)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [01:22, 1817.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>input_encoder_0</th>\n",
       "      <th>encoder_0</th>\n",
       "      <th>encoder_1</th>\n",
       "      <th>decoder_2</th>\n",
       "      <th>decoder_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-4.18, -3.123, -4.426, -4.566, -4.31, -2.686,...</td>\n",
       "      <td>[-4.62, 4.6, 2.79, 15.914, -1.982, -2.559, 5.1...</td>\n",
       "      <td>[6.508, 1.433, -52.7, -38.16, -38.25, -12.59, ...</td>\n",
       "      <td>[7.55385e-21, 1.8392207e-20, 2.3199758e-22, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-4.63, -3.096, -5.6, -4.703, -3.246, -1.735, ...</td>\n",
       "      <td>[-7.598, 0.609, -0.2153, 5.29, -9.86, -3.184, ...</td>\n",
       "      <td>[12.05, 10.93, -36.12, -36.56, -29.67, 3.033, ...</td>\n",
       "      <td>[1.4449236e-24, 4.4216033e-25, 4.4893125e-26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-4.066, -2.17, -6.2, -4.164, -3.432, -2.014, ...</td>\n",
       "      <td>[-18.94, 3.182, 2.537, 11.49, -2.59, 0.2343, 4...</td>\n",
       "      <td>[0.7256, 4.98, -35.34, -37.5, -25.62, 5.58, -3...</td>\n",
       "      <td>[2.7595757e-20, 2.179792e-20, 4.4423396e-21, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-2.775, -1.37, -4.523, -3.41, -4.156, -1.383,...</td>\n",
       "      <td>[5.34, 1.092, -11.47, -10.125, -0.466, 5.734, ...</td>\n",
       "      <td>[10.21, -34.06, -37.0, -33.8, -25.62, 10.49, -...</td>\n",
       "      <td>[1.5042852e-22, 2.2871306e-21, 9.459297e-22, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-4.67, -0.6133, -1.974, -2.314, -2.18, -0.874...</td>\n",
       "      <td>[-0.597, 3.434, 1.5205, -2.152, 10.56, 3.992, ...</td>\n",
       "      <td>[17.22, -14.41, -38.8, -25.06, -25.89, -11.04,...</td>\n",
       "      <td>[5.825696e-17, 1.9044598e-17, 1.09265556e-16, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                    input_encoder_0  \\\n",
       "0      0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2      2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                           encoder_0  \\\n",
       "0  [-4.18, -3.123, -4.426, -4.566, -4.31, -2.686,...   \n",
       "1  [-4.63, -3.096, -5.6, -4.703, -3.246, -1.735, ...   \n",
       "2  [-4.066, -2.17, -6.2, -4.164, -3.432, -2.014, ...   \n",
       "3  [-2.775, -1.37, -4.523, -3.41, -4.156, -1.383,...   \n",
       "4  [-4.67, -0.6133, -1.974, -2.314, -2.18, -0.874...   \n",
       "\n",
       "                                           encoder_1  \\\n",
       "0  [-4.62, 4.6, 2.79, 15.914, -1.982, -2.559, 5.1...   \n",
       "1  [-7.598, 0.609, -0.2153, 5.29, -9.86, -3.184, ...   \n",
       "2  [-18.94, 3.182, 2.537, 11.49, -2.59, 0.2343, 4...   \n",
       "3  [5.34, 1.092, -11.47, -10.125, -0.466, 5.734, ...   \n",
       "4  [-0.597, 3.434, 1.5205, -2.152, 10.56, 3.992, ...   \n",
       "\n",
       "                                           decoder_2  \\\n",
       "0  [6.508, 1.433, -52.7, -38.16, -38.25, -12.59, ...   \n",
       "1  [12.05, 10.93, -36.12, -36.56, -29.67, 3.033, ...   \n",
       "2  [0.7256, 4.98, -35.34, -37.5, -25.62, 5.58, -3...   \n",
       "3  [10.21, -34.06, -37.0, -33.8, -25.62, 10.49, -...   \n",
       "4  [17.22, -14.41, -38.8, -25.06, -25.89, -11.04,...   \n",
       "\n",
       "                                           decoder_3  \n",
       "0  [7.55385e-21, 1.8392207e-20, 2.3199758e-22, 1....  \n",
       "1  [1.4449236e-24, 4.4216033e-25, 4.4893125e-26, ...  \n",
       "2  [2.7595757e-20, 2.179792e-20, 4.4423396e-21, 5...  \n",
       "3  [1.5042852e-22, 2.2871306e-21, 9.459297e-22, 2...  \n",
       "4  [5.825696e-17, 1.9044598e-17, 1.09265556e-16, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from small_model import DeepAutoencoder\n",
    "\n",
    "model = DeepAutoencoder(input_size = 641)\n",
    "model.load_state_dict(torch.load('models/model_BCE_small_900.pt'))\n",
    "\n",
    "\n",
    "\n",
    "activation = {}\n",
    "def get_output_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def get_input_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation['input_'+name] = input[0].detach()\n",
    "    return hook\n",
    "\n",
    "model.encoder_0.register_forward_hook(get_input_activation('encoder_0'))\n",
    "model.encoder_0.register_forward_hook(get_output_activation('encoder_0'))\n",
    "model.encoder_1.register_forward_hook(get_output_activation('encoder_1'))\n",
    "#model.encoder_2.register_forward_hook(get_output_activation('encoder_2'))\n",
    "#model.encoder_3.register_forward_hook(get_output_activation('encoder_3'))\n",
    "#model.decoder_0.register_forward_hook(get_output_activation('decoder_0'))\n",
    "#model.decoder_1.register_forward_hook(get_output_activation('decoder_1'))\n",
    "model.decoder_2.register_forward_hook(get_output_activation('decoder_2'))\n",
    "model.decoder_3.register_forward_hook(get_output_activation('decoder_3'))\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "df_activations = get_activations(model, df)\n",
    "df_activations.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: input_encoder_0, y: has_contested_open_file, model_name: .RidgeClassifier\n",
      "X: input_encoder_0, y: white_double_pawn, model_name: .RidgeClassifier\n",
      "X: input_encoder_0, y: white_queen, model_name: .RidgeClassifier\n",
      "X: encoder_0, y: has_contested_open_file, model_name: .RidgeClassifier\n",
      "X: encoder_0, y: white_double_pawn, model_name: .RidgeClassifier\n",
      "X: encoder_0, y: white_queen, model_name: .RidgeClassifier\n",
      "X: encoder_1, y: has_contested_open_file, model_name: .RidgeClassifier\n",
      "X: encoder_1, y: white_double_pawn, model_name: .RidgeClassifier\n",
      "X: encoder_1, y: white_queen, model_name: .RidgeClassifier\n",
      "X: decoder_2, y: has_contested_open_file, model_name: .RidgeClassifier\n",
      "X: decoder_2, y: white_double_pawn, model_name: .RidgeClassifier\n",
      "X: decoder_2, y: white_queen, model_name: .RidgeClassifier\n",
      "X: decoder_3, y: has_contested_open_file, model_name: .RidgeClassifier\n",
      "X: decoder_3, y: white_double_pawn, model_name: .RidgeClassifier\n",
      "X: decoder_3, y: white_queen, model_name: .RidgeClassifier\n",
      "X: input_encoder_0, y: has_contested_open_file, model_name: .LGBMClassifier\n",
      "X: input_encoder_0, y: white_double_pawn, model_name: .LGBMClassifier\n",
      "X: input_encoder_0, y: white_queen, model_name: .LGBMClassifier\n",
      "X: encoder_0, y: has_contested_open_file, model_name: .LGBMClassifier\n",
      "X: encoder_0, y: white_double_pawn, model_name: .LGBMClassifier\n",
      "X: encoder_0, y: white_queen, model_name: .LGBMClassifier\n",
      "X: encoder_1, y: has_contested_open_file, model_name: .LGBMClassifier\n",
      "X: encoder_1, y: white_double_pawn, model_name: .LGBMClassifier\n",
      "X: encoder_1, y: white_queen, model_name: .LGBMClassifier\n",
      "X: decoder_2, y: has_contested_open_file, model_name: .LGBMClassifier\n",
      "X: decoder_2, y: white_double_pawn, model_name: .LGBMClassifier\n",
      "X: decoder_2, y: white_queen, model_name: .LGBMClassifier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_size = 0.33\n",
    "metric = classification_cost\n",
    "\n",
    "verbose = False\n",
    "\n",
    "undersample = RandomUnderSampler(\n",
    "    sampling_strategy=\"majority\"\n",
    ")\n",
    "\n",
    "concept_models = [\n",
    "    RidgeClassifier(), \n",
    "    LGBMClassifier()\n",
    "    ]\n",
    "\n",
    "input_names = [\n",
    "    'input_encoder_0', \n",
    "    'encoder_0', \n",
    "    'encoder_1', \n",
    "    #'encoder_2', \n",
    "    #'encoder_3', \n",
    "    #'decoder_0', \n",
    "    #'decoder_1', \n",
    "    'decoder_2',\n",
    "    'decoder_3'\n",
    "    ]\n",
    "\n",
    "target_names = [\n",
    "    'has_contested_open_file',\n",
    "    'white_double_pawn', \n",
    "    'white_queen'\n",
    "    ]\n",
    "\n",
    "df_results = train_concept_models(concept_models, input_names, target_names, df_activations, df, undersample, test_size, metric, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_304003/3745314124.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_results' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "plot_results(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_medium import DeepAutoencoder\n",
    "\n",
    "model = DeepAutoencoder(input_size = 641)\n",
    "model.load_state_dict(torch.load('models/model_BCE_medium_900.pt'))\n",
    "\n",
    "\n",
    "\n",
    "activation = {}\n",
    "def get_output_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def get_input_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation['input_'+name] = input[0].detach()\n",
    "    return hook\n",
    "\n",
    "model.encoder_0.register_forward_hook(get_input_activation('encoder_0'))\n",
    "model.encoder_0.register_forward_hook(get_output_activation('encoder_0'))\n",
    "model.encoder_1.register_forward_hook(get_output_activation('encoder_1'))\n",
    "model.encoder_2.register_forward_hook(get_output_activation('encoder_2'))\n",
    "#model.encoder_3.register_forward_hook(get_output_activation('encoder_3'))\n",
    "#model.decoder_0.register_forward_hook(get_output_activation('decoder_0'))\n",
    "model.decoder_1.register_forward_hook(get_output_activation('decoder_1'))\n",
    "model.decoder_2.register_forward_hook(get_output_activation('decoder_2'))\n",
    "model.decoder_3.register_forward_hook(get_output_activation('decoder_3'))\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "df_activations = get_activations(model, df)\n",
    "df_activations.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_size = 0.33\n",
    "metric = classification_cost\n",
    "\n",
    "verbose = False\n",
    "\n",
    "undersample = RandomUnderSampler(\n",
    "    sampling_strategy=\"majority\"\n",
    ")\n",
    "\n",
    "concept_models = [\n",
    "    RidgeClassifier(), \n",
    "    LGBMClassifier()\n",
    "    ]\n",
    "\n",
    "input_names = [\n",
    "    'input_encoder_0', \n",
    "    'encoder_0', \n",
    "    'encoder_1', \n",
    "    'encoder_2', \n",
    "    #'encoder_3', \n",
    "    #'decoder_0', \n",
    "    'decoder_1', \n",
    "    'decoder_2',\n",
    "    'decoder_3'\n",
    "    ]\n",
    "\n",
    "target_names = [\n",
    "    'has_contested_open_file',\n",
    "    'white_double_pawn', \n",
    "    'white_queen'\n",
    "    ]\n",
    "\n",
    "df_results = train_concept_models(concept_models, input_names, target_names, df_activations, df, undersample, test_size, metric, verbose = verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DeepAutoencoder\n",
    "\n",
    "model = DeepAutoencoder(input_size = 641)\n",
    "model.load_state_dict(torch.load('models/model_BCE_700.pt'))\n",
    "\n",
    "\n",
    "\n",
    "activation = {}\n",
    "def get_output_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def get_input_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation['input_'+name] = input[0].detach()\n",
    "    return hook\n",
    "\n",
    "model.encoder_0.register_forward_hook(get_input_activation('encoder_0'))\n",
    "model.encoder_0.register_forward_hook(get_output_activation('encoder_0'))\n",
    "model.encoder_1.register_forward_hook(get_output_activation('encoder_1'))\n",
    "model.encoder_2.register_forward_hook(get_output_activation('encoder_2'))\n",
    "model.encoder_3.register_forward_hook(get_output_activation('encoder_3'))\n",
    "model.decoder_0.register_forward_hook(get_output_activation('decoder_0'))\n",
    "model.decoder_1.register_forward_hook(get_output_activation('decoder_1'))\n",
    "model.decoder_2.register_forward_hook(get_output_activation('decoder_2'))\n",
    "model.decoder_3.register_forward_hook(get_output_activation('decoder_3'))\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "df_activations = get_activations(model, df)\n",
    "df_activations.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_size = 0.33\n",
    "metric = classification_cost\n",
    "\n",
    "verbose = False\n",
    "\n",
    "undersample = RandomUnderSampler(\n",
    "    sampling_strategy=\"majority\"\n",
    ")\n",
    "\n",
    "concept_models = [\n",
    "    RidgeClassifier(), \n",
    "    LGBMClassifier()\n",
    "    ]\n",
    "\n",
    "input_names = [\n",
    "    'input_encoder_0', \n",
    "    'encoder_0', \n",
    "    'encoder_1', \n",
    "    'encoder_2', \n",
    "    'encoder_3', \n",
    "    'decoder_0', \n",
    "    'decoder_1', \n",
    "    'decoder_2',\n",
    "    'decoder_3'\n",
    "    ]\n",
    "\n",
    "target_names = [\n",
    "    'has_contested_open_file',\n",
    "    'white_double_pawn', \n",
    "    'white_queen'\n",
    "    ]\n",
    "\n",
    "df_results = train_concept_models(concept_models, input_names, target_names, df_activations, df, undersample, test_size, metric, verbose = verbose)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0001719194acec2445408d856df89780a2f98fad55a466606d2632dd4f5ece98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
