{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum extensions \n",
    "\n",
    "- [ ] Removing a chosen number of pieces (instead of starting with empty board)\n",
    "- [ ] Removing similar pieces at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New S V S attribution:  17%|█▋        | 199/1201 [01:01<06:46,  2.46it/s]"
     ]
    }
   ],
   "source": [
    "from captum.attr._core.shapley_value import *\n",
    "from captum._utils.common import (\n",
    "    _expand_additional_forward_args,\n",
    "    _expand_target,\n",
    "    _format_additional_forward_args,\n",
    "    _format_output,\n",
    "    _format_tensor_into_tuples,\n",
    "    _is_tuple,\n",
    "    _run_forward,\n",
    ")\n",
    "from captum.attr._utils.common import (\n",
    "    _construct_default_feature_mask,\n",
    "    _find_output_mode_and_verify,\n",
    "    _format_input_baseline,\n",
    "    _tensorize_baseline,\n",
    ")\n",
    "import pdb\n",
    "\n",
    "\n",
    "class NewSVS(ShapleyValueSampling):\n",
    "    @log_usage()\n",
    "    def new_attribute(\n",
    "        self,\n",
    "        inputs: TensorOrTupleOfTensorsGeneric,\n",
    "        baselines: BaselineType = None,\n",
    "        target: TargetType = None,\n",
    "        additional_forward_args: Any = None,\n",
    "        feature_mask: Union[None, TensorOrTupleOfTensorsGeneric] = None,\n",
    "        n_samples: int = 25,\n",
    "        perturbations_per_eval: int = 1,\n",
    "        show_progress: bool = False,\n",
    "        num_pertub: int = 5,\n",
    "    ) -> TensorOrTupleOfTensorsGeneric:\n",
    "        # Keeps track whether original input is a tuple or not before\n",
    "        # converting it into a tuple.\n",
    "        is_inputs_tuple = _is_tuple(inputs)\n",
    "        inputs, baselines = _format_input_baseline(inputs, baselines)\n",
    "        additional_forward_args = _format_additional_forward_args(\n",
    "            additional_forward_args\n",
    "        )\n",
    "        feature_mask = (\n",
    "            _format_tensor_into_tuples(feature_mask)\n",
    "            if feature_mask is not None\n",
    "            else None\n",
    "        )\n",
    "        assert (\n",
    "            isinstance(perturbations_per_eval, int) and perturbations_per_eval >= 1\n",
    "        ), \"Ablations per evaluation must be at least 1.\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            baselines = _tensorize_baseline(inputs, baselines)\n",
    "            num_examples = inputs[0].shape[0]\n",
    "\n",
    "            if feature_mask is None:\n",
    "                feature_mask, total_features = _construct_default_feature_mask(inputs)\n",
    "            else:\n",
    "                total_features = int(\n",
    "                    max(torch.max(single_mask).item() for single_mask in feature_mask)\n",
    "                    + 1\n",
    "                )\n",
    "\n",
    "            if show_progress:\n",
    "                attr_progress = progress(\n",
    "                    desc=f\"{self.get_name()} attribution\",\n",
    "                    total=self._get_n_evaluations(\n",
    "                        min(num_pertub, total_features), n_samples, perturbations_per_eval\n",
    "                    )\n",
    "                    + 1,  # add 1 for the initial eval\n",
    "                )\n",
    "                attr_progress.update(0)\n",
    "\n",
    "            initial_eval = _run_forward(\n",
    "                self.forward_func, baselines, target, additional_forward_args\n",
    "            )\n",
    "\n",
    "            if show_progress:\n",
    "                attr_progress.update()\n",
    "\n",
    "            agg_output_mode = _find_output_mode_and_verify(\n",
    "                initial_eval, num_examples, perturbations_per_eval, feature_mask\n",
    "            )\n",
    "\n",
    "            # Initialize attribution totals and counts\n",
    "            total_attrib = [\n",
    "                torch.zeros_like(\n",
    "                    input[0:1] if agg_output_mode else input, dtype=torch.float\n",
    "                )\n",
    "                for input in inputs\n",
    "            ]\n",
    "            total_iter_count = [\n",
    "                torch.zeros_like(\n",
    "                    input[0:1] if agg_output_mode else input, dtype=torch.float\n",
    "                )\n",
    "                for input in inputs\n",
    "            ]\n",
    "            iter_count = 0\n",
    "            # Iterate for number of samples, generate a permutation of the features\n",
    "            # and evalute the incremental increase for each feature.\n",
    "            for feature_permutation in self.permutation_generator(\n",
    "                total_features, n_samples\n",
    "            ):\n",
    "                iter_count += 1\n",
    "                prev_results = initial_eval\n",
    "                is_first = True\n",
    "                for (\n",
    "                    current_inputs,\n",
    "                    current_add_args,\n",
    "                    current_target,\n",
    "                    current_masks,\n",
    "                ) in self._perturbation_generator(\n",
    "                    inputs,\n",
    "                    additional_forward_args,\n",
    "                    target,\n",
    "                    baselines,\n",
    "                    feature_mask,\n",
    "                    feature_permutation,\n",
    "                    perturbations_per_eval,\n",
    "                    num_perturb=num_pertub,\n",
    "                ):\n",
    "                    if is_first:\n",
    "\n",
    "                        modified_eval = _run_forward(\n",
    "                            self.forward_func,\n",
    "                            current_inputs,\n",
    "                            current_target,\n",
    "                            current_add_args,\n",
    "                        )\n",
    "                        prev_results = modified_eval\n",
    "\n",
    "\n",
    "                        is_first = False\n",
    "                    else:\n",
    "                        if sum(torch.sum(mask).item() for mask in current_masks) == 0:\n",
    "                            warnings.warn(\n",
    "                                \"Feature mask is missing some integers between 0 and \"\n",
    "                                \"num_features, for optimal performance, make sure each\"\n",
    "                                \" consecutive integer corresponds to a feature.\"\n",
    "                            )\n",
    "                        # modified_eval dimensions: 1D tensor with length\n",
    "                        # equal to #num_examples * #features in batch\n",
    "                        modified_eval = _run_forward(\n",
    "                            self.forward_func,\n",
    "                            current_inputs,\n",
    "                            current_target,\n",
    "                            current_add_args,\n",
    "                        )\n",
    "                        if show_progress:\n",
    "                            attr_progress.update()\n",
    "\n",
    "                        if agg_output_mode:\n",
    "                            eval_diff = modified_eval - prev_results\n",
    "                            prev_results = modified_eval\n",
    "                        else:\n",
    "                            all_eval = torch.cat((prev_results, modified_eval), dim=0)\n",
    "                            eval_diff = all_eval[num_examples:] - all_eval[:-num_examples]\n",
    "                            prev_results = all_eval[-num_examples:]\n",
    "                        for j in range(len(total_attrib)):\n",
    "                            current_eval_diff = eval_diff\n",
    "                            if not agg_output_mode:\n",
    "                                # current_eval_diff dimensions:\n",
    "                                # (#features in batch, #num_examples, 1,.. 1)\n",
    "                                # (contains 1 more dimension than inputs). This adds extra\n",
    "                                # dimensions of 1 to make the tensor broadcastable with the\n",
    "                                # inputs tensor.\n",
    "                                current_eval_diff = current_eval_diff.reshape(\n",
    "                                    (-1, num_examples) + (len(inputs[j].shape) - 1) * (1,)\n",
    "                                )\n",
    "                                \n",
    "                            total_attrib[j] += (\n",
    "                                current_eval_diff * current_masks[j].float()\n",
    "                            ).sum(dim=0)\n",
    "\n",
    "                            total_iter_count[j] += (\n",
    "                                current_masks[j].float()\n",
    "                            ).sum(dim=0)\n",
    "                            #print(f'current_eval_diff: {current_eval_diff.item()}')\n",
    "                            #print(total_attrib)\n",
    "\n",
    "            if show_progress:\n",
    "                attr_progress.close()\n",
    "\n",
    "            # Divide total attributions by number of random permutations and return\n",
    "            # formatted attributions.\n",
    "            attrib = tuple(\n",
    "                tensor_attrib_total / _iter_count for (_iter_count, tensor_attrib_total) in zip(total_iter_count, total_attrib)\n",
    "            )\n",
    "            formatted_attr = _format_output(is_inputs_tuple, attrib)\n",
    "        return formatted_attr\n",
    "\n",
    "\n",
    "    def _perturbation_generator(\n",
    "        self,\n",
    "        inputs: Tuple[Tensor, ...],\n",
    "        additional_args: Any,\n",
    "        target: TargetType,\n",
    "        baselines: Tuple[Tensor, ...],\n",
    "        input_masks: TensorOrTupleOfTensorsGeneric,\n",
    "        feature_permutation: Sequence[int],\n",
    "        perturbations_per_eval: int,\n",
    "        num_perturb: int = 5,\n",
    "    ) -> Iterable[Tuple[Tuple[Tensor, ...], Any, TargetType, Tuple[Tensor, ...]]]:\n",
    "        \"\"\"\n",
    "        This method is a generator which yields each perturbation to be evaluated\n",
    "        including inputs, additional_forward_args, targets, and mask.\n",
    "        \"\"\"\n",
    "        # current_tensors starts at baselines and includes each additional feature as\n",
    "        # added based on the permutation order.\n",
    "        current_tensors = baselines\n",
    "        current_tensors_list = []\n",
    "        current_mask_list = []\n",
    "\n",
    "        # Compute repeated additional args and targets\n",
    "        additional_args_repeated = (\n",
    "            _expand_additional_forward_args(additional_args, perturbations_per_eval)\n",
    "            if additional_args is not None\n",
    "            else None\n",
    "        )\n",
    "        target_repeated = _expand_target(target, perturbations_per_eval)\n",
    "\n",
    "        lower_value = max(0, len(feature_permutation) - num_perturb)\n",
    "        for i in range(lower_value, len(feature_permutation)):\n",
    "            current_tensors = tuple(\n",
    "                current * (~(mask == feature_permutation[i])).to(current.dtype)\n",
    "                + input * (mask == feature_permutation[i]).to(input.dtype)\n",
    "                for input, current, mask in zip(inputs, current_tensors, input_masks)\n",
    "            )\n",
    "            current_tensors_list.append(current_tensors)\n",
    "            current_mask_list.append(\n",
    "                tuple(mask == feature_permutation[i] for mask in input_masks)\n",
    "            )\n",
    "            if len(current_tensors_list) == perturbations_per_eval:\n",
    "                combined_inputs = tuple(\n",
    "                    torch.cat(aligned_tensors, dim=0)\n",
    "                    for aligned_tensors in zip(*current_tensors_list)\n",
    "                )\n",
    "                combined_masks = tuple(\n",
    "                    torch.stack(aligned_masks, dim=0)\n",
    "                    for aligned_masks in zip(*current_mask_list)\n",
    "                )\n",
    "                yield (\n",
    "                    combined_inputs,\n",
    "                    additional_args_repeated,\n",
    "                    target_repeated,\n",
    "                    combined_masks,\n",
    "                )\n",
    "                current_tensors_list = []\n",
    "                current_mask_list = []\n",
    "\n",
    "        # Create batch with remaining evaluations, may not be a complete batch\n",
    "        # (= perturbations_per_eval)\n",
    "        if len(current_tensors_list) != 0:\n",
    "            additional_args_repeated = (\n",
    "                _expand_additional_forward_args(\n",
    "                    additional_args, len(current_tensors_list)\n",
    "                )\n",
    "                if additional_args is not None\n",
    "                else None\n",
    "            )\n",
    "            target_repeated = _expand_target(target, len(current_tensors_list))\n",
    "            combined_inputs = tuple(\n",
    "                torch.cat(aligned_tensors, dim=0)\n",
    "                for aligned_tensors in zip(*current_tensors_list)\n",
    "            )\n",
    "            combined_masks = tuple(\n",
    "                torch.stack(aligned_masks, dim=0)\n",
    "                for aligned_masks in zip(*current_mask_list)\n",
    "            )\n",
    "            yield (\n",
    "                combined_inputs,\n",
    "                additional_args_repeated,\n",
    "                target_repeated,\n",
    "                combined_masks,\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "from utils import eval_class, plot_chess_board\n",
    "import matplotlib.pyplot as plt\n",
    "import chess\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import cairosvg\n",
    "import chess\n",
    "import chess.svg\n",
    "\n",
    "fen_string = \"3q2k1/5b1p/1pr2pp1/p2p4/3P2PP/1P1NQP2/P2R2K1/8 w - - 0 1\"\n",
    "non_king_pieces = [\"p\", \"b\", \"n\", \"r\", \"q\"]\n",
    "perturb_pieces = non_king_pieces\n",
    "color = None\n",
    "n_samples = 400\n",
    "method = 'shapley'\n",
    "num_pertub = 3\n",
    "\n",
    "board = chess.Board(fen_string)\n",
    "\n",
    "eval = eval_class(board, pertub_pieces=perturb_pieces, color=color)\n",
    "\n",
    "alg_svs = NewSVS(eval)\n",
    "\n",
    "mat = (\n",
    "    alg_svs.new_attribute(\n",
    "        eval.input,\n",
    "        baselines=0,\n",
    "        target=0,\n",
    "        perturbations_per_eval=1,\n",
    "        n_samples=n_samples,\n",
    "        show_progress=True,\n",
    "        num_pertub = num_pertub,\n",
    "    )\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .numpy()\n",
    ")\n",
    "\n",
    "\n",
    "board_mat = np.zeros((8, 8))\n",
    "for i in range(mat.shape[1]):\n",
    "    board_mat.ravel()[63 - eval.chosen_map_keys[i]] = mat[0, i]\n",
    "board_mat = np.fliplr(board_mat)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "\n",
    "plot_chess_board(board_mat, board,  ax1, ax2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebbee1726ed901440eee8d7a411c4ebe7db1ebe82ac11263f8328fe27ef956cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
