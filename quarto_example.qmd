---
title: "Stockfish Explainability"
format:
  html:
    code-fold: true
jupyter: python3
toc: true
number-sections: true
---

# Explainability and Stockfish

## Introduction
This document is a work in progress. It is intended to be a guide to the explainability features of Stockfish. It is not intended to be a guide to Stockfish itself. For that, please see the [Stockfish documentation](https://stockfishchess.org/).

## What is Explainability?
Explainability is the ability to understand why a machine learning model makes the decisions it does. It is a key component of the Explainable AI movement. It is also a key component of the Fairness, Accountability, and Transparency

## Explainability Methods
In the quest to understand why a machine learning model makes the decision it does we want to find out what it has learnt. The methods we will be using to explain Stockfish are:

- Feature Importance
- Saliency Maps
- Concept Probing  



# Chess

## Implemented Concepts

- **white_bishop_pair** - Is true if white has a bishop pair
- **white_knight_pair** - Is true if white has a knight pair
- **white_double_pawn** - Is true if white has a double pawn
- **white_isolated_pawn** - Is true if white has an isolated pawn
- **white_connected_rooks** - Is true if white has connected rooks
- **white_rook_on_open_file** - Is true if white has a rook on an open file
- **has_contested_open_file** - Is true if there is a contested open file
- **current_player_is_forking** - Is true if the current player is forking
- **current_player_can_fork** - Is true if the current player can fork
- **current_player_is_checking** - Is true if the current player is checking





# Concept Probing




```{python}
#| label: fig-polar
#| fig-cap: "A line plot on a polar axis"

import numpy as np
import matplotlib.pyplot as plt

r = np.arange(0, 2, 0.01)
theta = 2 * np.pi * r
fig, ax = plt.subplots(
  subplot_kw = {'projection': 'polar'} 
)
ax.plot(theta, r)
ax.set_rticks([0.5, 1, 1.5, 2])
ax.grid(True)
plt.show()
```


# Next Chapter